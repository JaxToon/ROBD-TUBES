{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd05b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3ca46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c721fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoNeo4jAggregator:\n",
    "    def __init__(self, mongo_uri: str, neo4j_uri: str, neo4j_user: str, neo4j_password: str):\n",
    "        # MongoDB Connection\n",
    "        self.mongo_client = pymongo.MongoClient(mongo_uri)\n",
    "        self.mongo_db = self.mongo_client['dbcafe']\n",
    "        self.transactions_collection = self.mongo_db['transactionlog']\n",
    "        \n",
    "        # Neo4j Connection\n",
    "        self.neo4j_driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))\n",
    "        \n",
    "        # Product price mapping (since prices aren't in MongoDB)\n",
    "        self.product_prices = {\n",
    "            \"C1\": 25000,  # Americano\n",
    "            \"C2\": 35000,  # Cappuccino\n",
    "            \"C3\": 40000,  # Latte\n",
    "            \"C4\": 20000,  # Espresso\n",
    "            \"C5\": 30000,  # Macchiato\n",
    "            \"C6\": 38000,  # Flat White\n",
    "            \"C7\": 45000,  # Mocha\n",
    "            \"C8\": 35000,  # Cold Brew\n",
    "            \"NC1\": 42000, # Matcha Latte\n",
    "            \"NC2\": 40000  # Chai Latte\n",
    "        }\n",
    "        \n",
    "    def close_connections(self):\n",
    "        \"\"\"Close database connections\"\"\"\n",
    "        self.mongo_client.close()\n",
    "        self.neo4j_driver.close()\n",
    "\n",
    "    def get_product_price(self, product_id: str) -> int:\n",
    "        \"\"\"Get product price with fallback\"\"\"\n",
    "        return self.product_prices.get(product_id, 30000)  # Default 30k\n",
    "\n",
    "    # ========== FIXED IDEA 1: Employee Performance Analysis ==========\n",
    "    def employee_performance_analysis(self, start_date: str, end_date: str) -> Dict[str, Any]:\n",
    "        logger.info(\"Starting employee performance analysis...\")\n",
    "        \n",
    "        # Get transaction data from MongoDB with fixed aggregation\n",
    "        mongo_pipeline = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"transaction_date\": {\n",
    "                        \"$gte\": start_date,\n",
    "                        \"$lte\": end_date\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"calculated_revenue\": {\n",
    "                        \"$multiply\": [\n",
    "                            \"$order_quantity\", \n",
    "                            30000  # Fixed price instead of trying to access non-existent field\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$id_employee\",\n",
    "                    \"total_transactions\": {\"$sum\": 1},\n",
    "                    \"total_revenue\": {\"$sum\": \"$calculated_revenue\"},\n",
    "                    \"avg_order_quantity\": {\"$avg\": \"$order_quantity\"},\n",
    "                    \"franchise_id\": {\"$first\": \"$id_franchise\"}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        mongo_results = list(self.transactions_collection.aggregate(mongo_pipeline))\n",
    "        \n",
    "        # Get employee data from Neo4j\n",
    "        with self.neo4j_driver.session() as session:\n",
    "            neo4j_query = \"\"\"\n",
    "            MATCH (e:Employee)\n",
    "            RETURN e.id as employee_id, e.name as employee_name, \n",
    "                   e.work_start_hour as start_hour, e.work_end_hour as end_hour,\n",
    "                   e.id_cafe as cafe_id\n",
    "            \"\"\"\n",
    "            try:\n",
    "                neo4j_results = session.run(neo4j_query).data()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Neo4j query failed, using empty results: {e}\")\n",
    "                neo4j_results = []\n",
    "        \n",
    "        # Combine results\n",
    "        combined_results = []\n",
    "        for mongo_emp in mongo_results:\n",
    "            emp_id = mongo_emp['_id']\n",
    "            neo4j_emp = next((e for e in neo4j_results if e['employee_id'] == emp_id), None)\n",
    "            \n",
    "            if neo4j_emp:\n",
    "                # Parse work hours (assuming format like \"07:00\")\n",
    "                try:\n",
    "                    start_hour = int(str(neo4j_emp['start_hour']).split(':')[0])\n",
    "                    end_hour = int(str(neo4j_emp['end_hour']).split(':')[0])\n",
    "                    work_hours = end_hour - start_hour\n",
    "                except:\n",
    "                    work_hours = 8  # Default\n",
    "                \n",
    "                performance_score = mongo_emp['total_revenue'] / work_hours if work_hours > 0 else 0\n",
    "                \n",
    "                combined_results.append({\n",
    "                    'employee_id': emp_id,\n",
    "                    'employee_name': neo4j_emp['employee_name'],\n",
    "                    'cafe_id': neo4j_emp.get('cafe_id', 'Unknown'),\n",
    "                    'total_transactions': mongo_emp['total_transactions'],\n",
    "                    'total_revenue': mongo_emp['total_revenue'],\n",
    "                    'avg_order_quantity': mongo_emp['avg_order_quantity'],\n",
    "                    'work_hours': work_hours,\n",
    "                    'performance_score': performance_score,\n",
    "                    'revenue_per_hour': performance_score\n",
    "                })\n",
    "            else:\n",
    "                # Include MongoDB data even if Neo4j data is missing\n",
    "                combined_results.append({\n",
    "                    'employee_id': emp_id,\n",
    "                    'employee_name': f'Employee {emp_id}',\n",
    "                    'cafe_id': mongo_emp.get('franchise_id', 'Unknown'),\n",
    "                    'total_transactions': mongo_emp['total_transactions'],\n",
    "                    'total_revenue': mongo_emp['total_revenue'],\n",
    "                    'avg_order_quantity': mongo_emp['avg_order_quantity'],\n",
    "                    'work_hours': 8,  # Default work hours\n",
    "                    'performance_score': mongo_emp['total_revenue'] / 8,\n",
    "                    'revenue_per_hour': mongo_emp['total_revenue'] / 8\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'analysis_period': f\"{start_date} to {end_date}\",\n",
    "            'employee_performance': sorted(combined_results, key=lambda x: x['performance_score'], reverse=True)\n",
    "        }\n",
    "\n",
    "    # ========== FIXED IDEA 2: Regional Product Popularity ==========\n",
    "    def regional_product_analysis(self) -> Dict[str, Any]:\n",
    "        logger.info(\"Starting regional product analysis...\")\n",
    "        \n",
    "        # Since location data is missing from sample, we'll analyze by franchise\n",
    "        mongo_pipeline = [\n",
    "            {\n",
    "                \"$unwind\": \"$product\"  # Unwind the product array\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": {\n",
    "                        \"franchise_id\": \"$id_franchise\",\n",
    "                        \"product_id\": \"$product.id_product\",\n",
    "                        \"product_name\": \"$product.name\"\n",
    "                    },\n",
    "                    \"total_quantity\": {\"$sum\": \"$product.quantity\"},\n",
    "                    \"total_orders\": {\"$sum\": 1},\n",
    "                    \"avg_order_size\": {\"$avg\": \"$order_quantity\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$_id.franchise_id\",\n",
    "                    \"products\": {\n",
    "                        \"$push\": {\n",
    "                            \"product_id\": \"$_id.product_id\",\n",
    "                            \"product_name\": \"$_id.product_name\",\n",
    "                            \"total_quantity\": \"$total_quantity\",\n",
    "                            \"total_orders\": \"$total_orders\",\n",
    "                            \"avg_order_size\": \"$avg_order_size\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"franchise_total_orders\": {\"$sum\": \"$total_orders\"}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        mongo_results = list(self.transactions_collection.aggregate(mongo_pipeline))\n",
    "        \n",
    "        # Get product category data from Neo4j\n",
    "        with self.neo4j_driver.session() as session:\n",
    "            neo4j_query = \"\"\"\n",
    "            MATCH (p:Product)\n",
    "            RETURN p.id_product as product_id, p.name as product_name, \n",
    "                   p.category as category, p.price as price\n",
    "            \"\"\"\n",
    "            try:\n",
    "                product_data = {item['product_id']: item for item in session.run(neo4j_query).data()}\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to get product data from Neo4j: {e}\")\n",
    "                product_data = {}\n",
    "        \n",
    "        # Enhance results with product categories\n",
    "        enhanced_results = []\n",
    "        for franchise_data in mongo_results:\n",
    "            enhanced_products = []\n",
    "            for product in franchise_data['products']:\n",
    "                product_info = product_data.get(product['product_id'], {})\n",
    "                enhanced_product = {\n",
    "                    **product,\n",
    "                    'category': product_info.get('category', 'Coffee'),  # Default category\n",
    "                    'price': self.get_product_price(product['product_id']),\n",
    "                    'popularity_score': product['total_orders'] / franchise_data['franchise_total_orders'] if franchise_data['franchise_total_orders'] > 0 else 0\n",
    "                }\n",
    "                enhanced_products.append(enhanced_product)\n",
    "            \n",
    "            enhanced_results.append({\n",
    "                'franchise_id': franchise_data['_id'],\n",
    "                'total_orders': franchise_data['franchise_total_orders'],\n",
    "                'products': sorted(enhanced_products, key=lambda x: x['popularity_score'], reverse=True)\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'franchise_analysis': enhanced_results,\n",
    "            'top_franchises': sorted(enhanced_results, key=lambda x: x['total_orders'], reverse=True)[:5]\n",
    "        }\n",
    "\n",
    "    # ========== FIXED IDEA 3: Franchise Growth Analysis ==========\n",
    "    def franchise_growth_analysis(self, months_back: int = 12) -> Dict[str, Any]:\n",
    "        logger.info(\"Starting franchise growth analysis...\")\n",
    "        \n",
    "        # Calculate date range\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=months_back * 30)\n",
    "        \n",
    "        # Get monthly transaction trends from MongoDB\n",
    "        mongo_pipeline = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"transaction_date\": {\n",
    "                        \"$gte\": start_date.strftime(\"%Y-%m-%d\"),\n",
    "                        \"$lte\": end_date.strftime(\"%Y-%m-%d\")\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"month_year\": {\"$substr\": [\"$transaction_date\", 0, 7]},  # Extract YYYY-MM\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": {\n",
    "                        \"franchise_id\": \"$id_franchise\",\n",
    "                        \"month\": \"$month_year\"\n",
    "                    },\n",
    "                    \"monthly_transactions\": {\"$sum\": 1},\n",
    "                    \"monthly_revenue\": {\"$sum\": \"$calculated_revenue\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$_id.franchise_id\",\n",
    "                    \"monthly_data\": {\n",
    "                        \"$push\": {\n",
    "                            \"month\": \"$_id.month\",\n",
    "                            \"transactions\": \"$monthly_transactions\",\n",
    "                            \"revenue\": \"$monthly_revenue\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"total_transactions\": {\"$sum\": \"$monthly_transactions\"},\n",
    "                    \"total_revenue\": {\"$sum\": \"$monthly_revenue\"}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        mongo_results = list(self.transactions_collection.aggregate(mongo_pipeline))\n",
    "        \n",
    "        # Get franchise data from Neo4j\n",
    "        with self.neo4j_driver.session() as session:\n",
    "            neo4j_query = \"\"\"\n",
    "            MATCH (f:Franchise)\n",
    "            RETURN f.id as franchise_id, f.name as franchise_name, \n",
    "                   f.year_established as year_established\n",
    "            \"\"\"\n",
    "            try:\n",
    "                franchise_data = {item['franchise_id']: item for item in session.run(neo4j_query).data()}\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to get franchise data: {e}\")\n",
    "                franchise_data = {}\n",
    "        \n",
    "        # Calculate growth metrics\n",
    "        growth_analysis = []\n",
    "        for franchise_info in mongo_results:\n",
    "            franchise_id = franchise_info['_id']\n",
    "            neo4j_info = franchise_data.get(franchise_id, {})\n",
    "            \n",
    "            # Calculate growth trend\n",
    "            monthly_data = sorted(franchise_info['monthly_data'], key=lambda x: x['month'])\n",
    "            if len(monthly_data) >= 2:\n",
    "                first_month_revenue = monthly_data[0]['revenue']\n",
    "                last_month_revenue = monthly_data[-1]['revenue']\n",
    "                growth_rate = ((last_month_revenue - first_month_revenue) / first_month_revenue * 100) if first_month_revenue > 0 else 0\n",
    "            else:\n",
    "                growth_rate = 0\n",
    "            \n",
    "            franchise_age = datetime.now().year - neo4j_info.get('year_established', datetime.now().year)\n",
    "            \n",
    "            growth_analysis.append({\n",
    "                'franchise_id': franchise_id,\n",
    "                'franchise_name': neo4j_info.get('franchise_name', f'Franchise {franchise_id}'),\n",
    "                'franchise_age_years': franchise_age,\n",
    "                'total_transactions': franchise_info['total_transactions'],\n",
    "                'total_revenue': franchise_info['total_revenue'],\n",
    "                'growth_rate_percent': growth_rate,\n",
    "                'monthly_trends': monthly_data,\n",
    "                'avg_monthly_revenue': franchise_info['total_revenue'] / len(monthly_data) if monthly_data else 0\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'analysis_period_months': months_back,\n",
    "            'franchise_growth': sorted(growth_analysis, key=lambda x: x['growth_rate_percent'], reverse=True),\n",
    "            'top_performers': sorted(growth_analysis, key=lambda x: x['total_revenue'], reverse=True)[:10]\n",
    "        }\n",
    "\n",
    "    # ========== FIXED IDEA 4: Cross-Selling Opportunity Analysis ==========\n",
    "    def cross_selling_analysis(self) -> Dict[str, Any]:\n",
    "        logger.info(\"Starting cross-selling analysis...\")\n",
    "        \n",
    "        # Get multi-product transactions\n",
    "        multi_product_pipeline = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"$expr\": {\"$gt\": [{\"$size\": \"$product\"}, 1]}  # More than 1 product\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"id_transaction\": 1,\n",
    "                    \"product_ids\": \"$product.id_product\",\n",
    "                    \"id_franchise\": 1,\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        multi_product_transactions = list(self.transactions_collection.aggregate(multi_product_pipeline))\n",
    "        \n",
    "        # Get product data from Neo4j\n",
    "        with self.neo4j_driver.session() as session:\n",
    "            neo4j_query = \"\"\"\n",
    "            MATCH (p:Product)\n",
    "            RETURN p.id_product as product_id, p.name as product_name, \n",
    "                   p.category as category\n",
    "            \"\"\"\n",
    "            try:\n",
    "                products = {item['product_id']: item for item in session.run(neo4j_query).data()}\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to get product data: {e}\")\n",
    "                products = {}\n",
    "        \n",
    "        # Analyze product combinations\n",
    "        product_combinations = {}\n",
    "        \n",
    "        for transaction in multi_product_transactions:\n",
    "            products_in_transaction = transaction['product_ids']\n",
    "            \n",
    "            # Analyze product pairs\n",
    "            for i, product1 in enumerate(products_in_transaction):\n",
    "                for product2 in products_in_transaction[i+1:]:\n",
    "                    pair = tuple(sorted([product1, product2]))\n",
    "                    product_combinations[pair] = product_combinations.get(pair, 0) + 1\n",
    "        \n",
    "        # Sort and format results\n",
    "        top_product_pairs = sorted(product_combinations.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "        \n",
    "        formatted_product_pairs = []\n",
    "        for (prod1, prod2), count in top_product_pairs:\n",
    "            prod1_info = products.get(prod1, {})\n",
    "            prod2_info = products.get(prod2, {})\n",
    "            formatted_product_pairs.append({\n",
    "                'product1': {'id': prod1, 'name': prod1_info.get('product_name', f'Product {prod1}')},\n",
    "                'product2': {'id': prod2, 'name': prod2_info.get('product_name', f'Product {prod2}')},\n",
    "                'frequency': count,\n",
    "                'confidence': count / len(multi_product_transactions) if multi_product_transactions else 0\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'analysis_summary': {\n",
    "                'total_multi_product_transactions': len(multi_product_transactions),\n",
    "                'unique_product_combinations': len(product_combinations)\n",
    "            },\n",
    "            'top_product_combinations': formatted_product_pairs\n",
    "        }\n",
    "\n",
    "    # ========== FIXED MongoDB-Only Analysis ==========\n",
    "    def mongodb_only_analysis(self) -> Dict[str, Any]:\n",
    "        logger.info(\"Running MongoDB-only analysis...\")\n",
    "        \n",
    "        # Transaction summary\n",
    "        total_transactions = self.transactions_collection.count_documents({})\n",
    "        \n",
    "        # Top employees by transaction count\n",
    "        employee_pipeline = [\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$id_employee\",\n",
    "                    \"transaction_count\": {\"$sum\": 1},\n",
    "                    \"total_revenue\": {\"$sum\": \"$calculated_revenue\"},\n",
    "                    \"avg_order_quantity\": {\"$avg\": \"$order_quantity\"}\n",
    "                }\n",
    "            },\n",
    "            {\"$sort\": {\"total_revenue\": -1}},\n",
    "            {\"$limit\": 10}\n",
    "        ]\n",
    "        \n",
    "        top_employees = list(self.transactions_collection.aggregate(employee_pipeline))\n",
    "        \n",
    "        # Top products (unwind the array first)\n",
    "        product_pipeline = [\n",
    "            {\"$unwind\": \"$product\"},\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$product.id_product\",\n",
    "                    \"product_name\": {\"$first\": \"$product.name\"},\n",
    "                    \"total_quantity\": {\"$sum\": \"$product.quantity\"},\n",
    "                    \"order_count\": {\"$sum\": 1}\n",
    "                }\n",
    "            },\n",
    "            {\"$sort\": {\"total_quantity\": -1}},\n",
    "            {\"$limit\": 10}\n",
    "        ]\n",
    "        \n",
    "        top_products = list(self.transactions_collection.aggregate(product_pipeline))\n",
    "        \n",
    "        # Franchise analysis\n",
    "        franchise_pipeline = [\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$id_franchise\",\n",
    "                    \"transaction_count\": {\"$sum\": 1},\n",
    "                    \"total_revenue\": {\"$sum\": \"$calculated_revenue\"}\n",
    "                }\n",
    "            },\n",
    "            {\"$sort\": {\"total_revenue\": -1}},\n",
    "            {\"$limit\": 10}\n",
    "        ]\n",
    "        \n",
    "        top_franchises = list(self.transactions_collection.aggregate(franchise_pipeline))\n",
    "        \n",
    "        return {\n",
    "            'summary': {\n",
    "                'total_transactions': total_transactions,\n",
    "                'analysis_type': 'MongoDB Only'\n",
    "            },\n",
    "            'top_employees': top_employees,\n",
    "            'top_products': top_products,\n",
    "            'top_franchises': top_franchises\n",
    "        }\n",
    "\n",
    "    # ========== FIXED Customer Segmentation ==========\n",
    "    def customer_segmentation_analysis(self) -> Dict[str, Any]:\n",
    "        logger.info(\"Starting customer segmentation analysis...\")\n",
    "        \n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$name\",  # Customer name as identifier\n",
    "                    \"total_spent\": {\"$sum\": \"$calculated_revenue\"},\n",
    "                    \"transaction_count\": {\"$sum\": 1},\n",
    "                    \"avg_order_value\": {\"$avg\": \"$calculated_revenue\"},\n",
    "                    \"preferred_franchises\": {\"$addToSet\": \"$id_franchise\"},\n",
    "                    \"last_transaction\": {\"$max\": \"$transaction_date\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"customer_segment\": {\n",
    "                        \"$switch\": {\n",
    "                            \"branches\": [\n",
    "                                {\n",
    "                                    \"case\": {\"$and\": [{\"$gte\": [\"$total_spent\", 500000]}, {\"$gte\": [\"$transaction_count\", 20]}]},\n",
    "                                    \"then\": \"VIP\"\n",
    "                                },\n",
    "                                {\n",
    "                                    \"case\": {\"$and\": [{\"$gte\": [\"$total_spent\", 200000]}, {\"$gte\": [\"$transaction_count\", 10]}]},\n",
    "                                    \"then\": \"Regular\"\n",
    "                                },\n",
    "                                {\n",
    "                                    \"case\": {\"$and\": [{\"$lte\": [\"$total_spent\", 100000]}, {\"$lte\": [\"$transaction_count\", 5]}]},\n",
    "                                    \"then\": \"Occasional\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"default\": \"New\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"franchise_loyalty\": {\"$size\": \"$preferred_franchises\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$customer_segment\",\n",
    "                    \"customer_count\": {\"$sum\": 1},\n",
    "                    \"avg_total_spent\": {\"$avg\": \"$total_spent\"},\n",
    "                    \"avg_transaction_count\": {\"$avg\": \"$transaction_count\"},\n",
    "                    \"avg_order_value\": {\"$avg\": \"$avg_order_value\"}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        segmentation_results = list(self.transactions_collection.aggregate(pipeline))\n",
    "        \n",
    "        return {\n",
    "            'customer_segments': segmentation_results,\n",
    "            'total_customers': sum(segment['customer_count'] for segment in segmentation_results)\n",
    "        }\n",
    "\n",
    "    # ========== Main Analysis Runner ==========\n",
    "    def run_comprehensive_analysis(self) -> Dict[str, Any]:\n",
    "        logger.info(\"Starting comprehensive analysis...\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        try:\n",
    "            # Employee Performance Analysis\n",
    "            try:\n",
    "                results['employee_performance'] = self.employee_performance_analysis(\n",
    "                    start_date=\"2020-01-01\", \n",
    "                    end_date=\"2025-12-31\"\n",
    "                )\n",
    "                logger.info(\"✓ Employee performance analysis completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Employee performance analysis failed: {e}\")\n",
    "                results['employee_performance'] = {'error': str(e)}\n",
    "            \n",
    "            # Regional Product Analysis\n",
    "            try:\n",
    "                results['regional_products'] = self.regional_product_analysis()\n",
    "                logger.info(\"✓ Regional product analysis completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Regional product analysis failed: {e}\")\n",
    "                results['regional_products'] = {'error': str(e)}\n",
    "            \n",
    "            # Franchise Growth Analysis\n",
    "            try:\n",
    "                results['franchise_growth'] = self.franchise_growth_analysis(months_back=12)\n",
    "                logger.info(\"✓ Franchise growth analysis completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Franchise growth analysis failed: {e}\")\n",
    "                results['franchise_growth'] = {'error': str(e)}\n",
    "            \n",
    "            # Cross-selling Analysis\n",
    "            try:\n",
    "                results['cross_selling'] = self.cross_selling_analysis()\n",
    "                logger.info(\"✓ Cross-selling analysis completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Cross-selling analysis failed: {e}\")\n",
    "                results['cross_selling'] = {'error': str(e)}\n",
    "            \n",
    "            # Customer segmentation\n",
    "            try:\n",
    "                results['customer_segmentation'] = self.customer_segmentation_analysis()\n",
    "                logger.info(\"✓ Customer segmentation completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Customer segmentation failed: {e}\")\n",
    "                results['customer_segmentation'] = {'error': str(e)}\n",
    "            \n",
    "            # # MongoDB-only analysis as backup\n",
    "            # try:\n",
    "            #     results['mongodb_analysis'] = self.mongodb_only_analysis()\n",
    "            #     logger.info(\"✓ MongoDB analysis completed\")\n",
    "            # except Exception as e:\n",
    "            #     logger.error(f\"MongoDB analysis failed: {e}\")\n",
    "            #     results['mongodb_analysis'] = {'error': str(e)}\n",
    "            \n",
    "            # logger.info(\"Comprehensive analysis completed!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Critical error during analysis: {str(e)}\")\n",
    "            results = {'error': 'Analysis failed', 'details': str(e)}\n",
    "        \n",
    "        return results\n",
    "\n",
    "    # ========== Data Validation ==========\n",
    "    def validate_data_structure(self) -> Dict[str, Any]:\n",
    "        logger.info(\"Validating data structure...\")\n",
    "        \n",
    "        validation_results = {\n",
    "            'mongodb': {},\n",
    "            'neo4j': {},\n",
    "            'recommendations': []\n",
    "        }\n",
    "        \n",
    "        # MongoDB validation\n",
    "        try:\n",
    "            sample_transaction = self.transactions_collection.find_one()\n",
    "            if sample_transaction:\n",
    "                validation_results['mongodb'] = {\n",
    "                    'sample_structure': {\n",
    "                        'fields': list(sample_transaction.keys()),\n",
    "                        'has_product_info': 'product' in sample_transaction,\n",
    "                        'product_is_array': isinstance(sample_transaction.get('product'), list),\n",
    "                        'has_employee_info': 'id_employee' in sample_transaction,\n",
    "                        'has_franchise_info': 'id_franchise' in sample_transaction\n",
    "                    },\n",
    "                    'total_documents': self.transactions_collection.count_documents({}),\n",
    "                    'sample_product_structure': sample_transaction.get('product', [])[:2] if sample_transaction.get('product') else []\n",
    "                }\n",
    "            else:\n",
    "                validation_results['mongodb']['error'] = 'No documents found'\n",
    "        except Exception as e:\n",
    "            validation_results['mongodb']['error'] = str(e)\n",
    "        \n",
    "        # Neo4j validation\n",
    "        try:\n",
    "            with self.neo4j_driver.session() as session:\n",
    "                node_counts = {}\n",
    "                for label in ['Employee', 'Product', 'Franchise']:\n",
    "                    try:\n",
    "                        result = session.run(f\"MATCH (n:{label}) RETURN count(n) as count\")\n",
    "                        node_counts[label] = result.single()['count']\n",
    "                    except Exception as e:\n",
    "                        node_counts[label] = f\"Error: {e}\"\n",
    "                \n",
    "                validation_results['neo4j']['node_counts'] = node_counts\n",
    "                \n",
    "        except Exception as e:\n",
    "            validation_results['neo4j']['error'] = str(e)\n",
    "        \n",
    "        return validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223dda0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Validating data structure...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA VALIDATION ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting comprehensive analysis...\n",
      "INFO:__main__:Starting employee performance analysis...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"mongodb\": {\n",
      "    \"sample_structure\": {\n",
      "      \"fields\": [\n",
      "        \"_id\",\n",
      "        \"id_transaction\",\n",
      "        \"id_franchise\",\n",
      "        \"id_employee\",\n",
      "        \"product\",\n",
      "        \"name\",\n",
      "        \"transaction_date\",\n",
      "        \"order_quantity\"\n",
      "      ],\n",
      "      \"has_product_info\": true,\n",
      "      \"product_is_array\": true,\n",
      "      \"has_employee_info\": true,\n",
      "      \"has_franchise_info\": true\n",
      "    },\n",
      "    \"total_documents\": 10000,\n",
      "    \"sample_product_structure\": [\n",
      "      {\n",
      "        \"id_product\": \"C3\",\n",
      "        \"name\": \"Latte\",\n",
      "        \"quantity\": 3\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"neo4j\": {\n",
      "    \"node_counts\": {\n",
      "      \"Employee\": 50,\n",
      "      \"Product\": 10,\n",
      "      \"Franchise\": 10\n",
      "    }\n",
      "  },\n",
      "  \"recommendations\": []\n",
      "}\n",
      "\n",
      "=== RUNNING COMPREHENSIVE ANALYSIS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 3, column: 22, offset: 53} for query: '\\n            MATCH (e:Employee)\\n            RETURN e.id as employee_id, e.name as employee_name, \\n                   e.work_start_hour as start_hour, e.work_end_hour as end_hour,\\n                   e.id_cafe as cafe_id\\n            '\n",
      "INFO:__main__:✓ Employee performance analysis completed\n",
      "INFO:__main__:Starting regional product analysis...\n",
      "INFO:__main__:✓ Regional product analysis completed\n",
      "INFO:__main__:Starting franchise growth analysis...\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 3, column: 22, offset: 54} for query: '\\n            MATCH (f:Franchise)\\n            RETURN f.id as franchise_id, f.name as franchise_name, \\n                   f.year_established as year_established\\n            '\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: year_established)} {position: line: 4, column: 22, offset: 122} for query: '\\n            MATCH (f:Franchise)\\n            RETURN f.id as franchise_id, f.name as franchise_name, \\n                   f.year_established as year_established\\n            '\n",
      "INFO:__main__:✓ Franchise growth analysis completed\n",
      "INFO:__main__:Starting cross-selling analysis...\n",
      "INFO:__main__:✓ Cross-selling analysis completed\n",
      "INFO:__main__:Starting customer segmentation analysis...\n",
      "INFO:__main__:✓ Customer segmentation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANALYSIS SUMMARY ===\n",
      "✓ Employee Performance: Success\n",
      "  - 50 employees analyzed\n",
      "  - Top performer: Employee 16 (Rp5,047,500.00/day)\n",
      "✓ Regional Products: Success\n",
      "  - 10 franchises analyzed\n",
      "✓ Franchise Growth: Success\n",
      "✓ Cross Selling: Success\n",
      "✓ Customer Segmentation: Success\n",
      "  - 9357 customers segmented\n",
      "    • Occasional: 2193 customers\n",
      "    • New: 7164 customers\n",
      "Database connections closed.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Database connection parameters\n",
    "    MONGO_URI = \"mongodb://localhost:27017/\"\n",
    "    URI = os.getenv(\"NEO4J_URI\")\n",
    "    USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "    PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "    \n",
    "    # Initialize aggregator\n",
    "    aggregator = MongoNeo4jAggregator(\n",
    "        mongo_uri=MONGO_URI,\n",
    "        neo4j_uri=URI,\n",
    "        neo4j_user=USERNAME,\n",
    "        neo4j_password=PASSWORD\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Validate data structure first\n",
    "        print(\"=== DATA VALIDATION ===\")\n",
    "        validation = aggregator.validate_data_structure()\n",
    "        print(json.dumps(validation, indent=2, default=str))\n",
    "        \n",
    "        # Run comprehensive analysis\n",
    "        print(\"\\n=== RUNNING COMPREHENSIVE ANALYSIS ===\")\n",
    "        results = aggregator.run_comprehensive_analysis()\n",
    "        \n",
    "        # # Save results to JSON file\n",
    "        # output_file = f'fixed_analysis_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "        # with open(output_file, 'w') as f:\n",
    "        #     json.dump(results, f, indent=2, default=str)\n",
    "        \n",
    "        # print(f\"\\nResults saved to: {output_file}\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n=== ANALYSIS SUMMARY ===\")\n",
    "        \n",
    "        for analysis_type, data in results.items():\n",
    "            if 'error' not in data:\n",
    "                print(f\"✓ {analysis_type.replace('_', ' ').title()}: Success\")\n",
    "                \n",
    "                # Print specific metrics for each analysis\n",
    "                if analysis_type == 'employee_performance':\n",
    "                    emp_count = len(data.get('employee_performance', []))\n",
    "                    print(f\"  - {emp_count} employees analyzed\")\n",
    "                    if emp_count > 0:\n",
    "                        top_performer = data['employee_performance'][0]\n",
    "                        print(f\"  - Top performer: {top_performer['employee_name']} (Rp{top_performer['revenue_per_hour']:,.2f}/day)\")\n",
    "                \n",
    "                elif analysis_type == 'regional_products':\n",
    "                    franchise_count = len(data.get('franchise_analysis', []))\n",
    "                    print(f\"  - {franchise_count} franchises analyzed\")\n",
    "                \n",
    "                elif analysis_type == 'customer_segmentation':\n",
    "                    total_customers = data.get('total_customers', 0)\n",
    "                    print(f\"  - {total_customers} customers segmented\")\n",
    "                    for segment in data.get('customer_segments', []):\n",
    "                        print(f\"    • {segment['_id']}: {segment['customer_count']} customers\")\n",
    "                \n",
    "                # elif analysis_type == 'mongodb_analysis':\n",
    "                #     total_trans = data['summary'].get('total_transactions', 0)\n",
    "                #     print(f\"  - {total_trans:,} total transactions processed\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"✗ {analysis_type.replace('_', ' ').title()}: {data['error']}\")\n",
    "        \n",
    "        # print(f\"\\n=== DETAILED RESULTS SAVED TO: {output_file} ===\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main execution failed: {str(e)}\")\n",
    "        print(f\"Analysis failed with error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Close connections\n",
    "        aggregator.close_connections()\n",
    "        print(\"Database connections closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
