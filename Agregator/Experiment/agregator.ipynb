{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44caeeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852c1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Akses data dari Neo4j\n",
    "uri = \"bolt://localhost:7687\"\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"jekialacarte\"))\n",
    "session = driver.session()\n",
    "\n",
    "\n",
    "#Akses data dari MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "db = client[\"dbcafe\"]\n",
    "collection = db[\"transactionlog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbe1403",
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceUnavailable",
     "evalue": "Couldn't connect to localhost:7687 (resolved to ()):\nFailed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\nFailed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:564\u001b[0m, in \u001b[0;36mBoltSocket._connect\u001b[1;34m(cls, resolved_address, timeout, keep_alive)\u001b[0m\n\u001b[0;32m    563\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  C: <OPEN> \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, resolved_address)\n\u001b[1;32m--> 564\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m s\u001b[38;5;241m.\u001b[39msettimeout(t)\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:750\u001b[0m, in \u001b[0;36mBoltSocket.connect\u001b[1;34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 750\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mBoltSocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m     s \u001b[38;5;241m=\u001b[39m BoltSocket\u001b[38;5;241m.\u001b[39m_secure(\n\u001b[0;32m    754\u001b[0m         s, resolved_address\u001b[38;5;241m.\u001b[39m_host_name, ssl_context\n\u001b[0;32m    755\u001b[0m     )\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:586\u001b[0m, in \u001b[0;36mBoltSocket._connect\u001b[1;34m(cls, resolved_address, timeout, keep_alive)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[1;32m--> 586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish connection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_address\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    588\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(reason \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    589\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m: Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m neo4j_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39msession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 63\u001b[0m     franchise_data \u001b[38;5;241m=\u001b[39m {item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfranchise_id\u001b[39m\u001b[38;5;124m'\u001b[39m]: item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneo4j_query\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata()}\n\u001b[0;32m     64\u001b[0m neo4j_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     65\u001b[0m neo4j_query_time \u001b[38;5;241m=\u001b[39m neo4j_end_time \u001b[38;5;241m-\u001b[39m neo4j_start_time\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:313\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\u001b[38;5;241m.\u001b[39m_buffer_all()\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_access_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    315\u001b[0m cx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:136\u001b[0m, in \u001b[0;36mSession._connect\u001b[1;34m(self, access_mode, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     access_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43macquire_kwargs\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_cancellation(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_connect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:184\u001b[0m, in \u001b[0;36mWorkspace._connect\u001b[1;34m(self, access_mode, auth, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m acquire_kwargs_ \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: access_mode,\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: acquisition_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliveness_check_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    182\u001b[0m }\n\u001b[0;32m    183\u001b[0m acquire_kwargs_\u001b[38;5;241m.\u001b[39mupdate(acquire_kwargs)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43macquire_kwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_access_mode \u001b[38;5;241m=\u001b[39m access_mode\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:597\u001b[0m, in \u001b[0;36mBoltPool.acquire\u001b[1;34m(self, access_mode, timeout, database, bookmarks, auth, liveness_check_timeout)\u001b[0m\n\u001b[0;32m    590\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <POOL> acquire direct connection, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_mode=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m, database=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    593\u001b[0m     access_mode,\n\u001b[0;32m    594\u001b[0m     database,\n\u001b[0;32m    595\u001b[0m )\n\u001b[0;32m    596\u001b[0m deadline \u001b[38;5;241m=\u001b[39m Deadline\u001b[38;5;241m.\u001b[39mfrom_timeout_or_deadline(timeout)\n\u001b[1;32m--> 597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:347\u001b[0m, in \u001b[0;36mIOPool._acquire\u001b[1;34m(self, address, auth, deadline, liveness_check_timeout)\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ClientError(\n\u001b[0;32m    343\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to obtain a connection from the pool within \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeadline\u001b[38;5;241m.\u001b[39moriginal_timeout\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124ms (timeout)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m             )\n\u001b[0;32m    346\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <POOL> trying to hand out new connection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:169\u001b[0m, in \u001b[0;36mIOPool._acquire_new_later.<locals>.connection_creator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ServiceUnavailable:\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeactivate(address)\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:560\u001b[0m, in \u001b[0;36mBoltPool.open.<locals>.opener\u001b[1;34m(addr, auth_manager, deadline)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopener\u001b[39m(addr, auth_manager, deadline):\n\u001b[1;32m--> 560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBolt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrouting_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:448\u001b[0m, in \u001b[0;36mBolt.open\u001b[1;34m(cls, address, auth_manager, deadline, routing_context, pool_config)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deadline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m Deadline(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 448\u001b[0m s, protocol_version, handshake, data \u001b[38;5;241m=\u001b[39m \u001b[43mBoltSocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_resolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m pool_config\u001b[38;5;241m.\u001b[39mprotocol_version \u001b[38;5;241m=\u001b[39m protocol_version\n\u001b[0;32m    459\u001b[0m \u001b[38;5;66;03m# Carry out Bolt subclass imports locally to avoid circular dependency\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# issues.\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# avoid new lines after imports for better readability and conciseness\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n",
      "File \u001b[1;32md:\\Kampus Merdeka MBKM\\Company Stuff\\.conda\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:784\u001b[0m, in \u001b[0;36mBoltSocket.connect\u001b[1;34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[0m\n\u001b[0;32m    782\u001b[0m resolved_address_strs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, resolved_addresses))\n\u001b[0;32m    783\u001b[0m error_strs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, errors))\n\u001b[1;32m--> 784\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddress\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(resolved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_address_strs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_strs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    788\u001b[0m ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merrors\u001b[39;00m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m: Couldn't connect to localhost:7687 (resolved to ()):\nFailed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\nFailed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "months_back = 12\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=months_back * 30)\n",
    "\n",
    "# MongoDB aggregation pipeline\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"transaction_date\": {\n",
    "                \"$gte\": start_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"$lte\": end_date.strftime(\"%Y-%m-%d\")\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"month_year\": {\"$substr\": [\"$transaction_date\", 0, 7]},\n",
    "            \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"franchise_id\": \"$id_franchise\",\n",
    "                \"month\": \"$month_year\"\n",
    "            },\n",
    "            \"monthly_transactions\": {\"$sum\": 1},\n",
    "            \"monthly_revenue\": {\"$sum\": \"$calculated_revenue\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$_id.franchise_id\",\n",
    "            \"monthly_data\": {\n",
    "                \"$push\": {\n",
    "                    \"month\": \"$_id.month\",\n",
    "                    \"transactions\": \"$monthly_transactions\",\n",
    "                    \"revenue\": \"$monthly_revenue\"\n",
    "                }\n",
    "            },\n",
    "            \"total_transactions\": {\"$sum\": \"$monthly_transactions\"},\n",
    "            \"total_revenue\": {\"$sum\": \"$monthly_revenue\"}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Get MongoDB results\n",
    "mongo_start_time = time.time()\n",
    "mongo_results = list(collection.aggregate(pipeline))\n",
    "mongo_end_time = time.time()\n",
    "mongo_query_time = mongo_end_time - mongo_start_time\n",
    "\n",
    "# Get Neo4j franchise data\n",
    "neo4j_query = \"\"\"\n",
    "MATCH (f:Franchise)\n",
    "RETURN f.id as franchise_id, f.name as franchise_name, \n",
    "       f.year_established as year_established\n",
    "\"\"\"\n",
    "\n",
    "neo4j_start_time = time.time()\n",
    "with driver.session() as session:\n",
    "    franchise_data = {item['franchise_id']: item for item in session.run(neo4j_query).data()}\n",
    "neo4j_end_time = time.time()\n",
    "neo4j_query_time = neo4j_end_time - neo4j_start_time\n",
    "\n",
    "# Process results\n",
    "growth_analysis = []\n",
    "for franchise in mongo_results:\n",
    "    franchise_id = franchise['_id']\n",
    "    franchise_info = franchise_data.get(franchise_id, {})\n",
    "    \n",
    "    # Sort monthly data by month\n",
    "    monthly_data = sorted(franchise['monthly_data'], key=lambda x: x['month'])\n",
    "    \n",
    "    # Calculate growth rate\n",
    "    growth_rate = 0\n",
    "    if len(monthly_data) >= 2:\n",
    "        first_revenue = monthly_data[0]['revenue']\n",
    "        last_revenue = monthly_data[-1]['revenue']\n",
    "        if first_revenue > 0:\n",
    "            growth_rate = ((last_revenue - first_revenue) / first_revenue) * 100\n",
    "    \n",
    "    # Calculate franchise age\n",
    "    franchise_age = datetime.now().year - franchise_info.get('year_established', datetime.now().year)\n",
    "    \n",
    "    # Build analysis record\n",
    "    growth_analysis.append({\n",
    "        'franchise_id': franchise_id,\n",
    "        'franchise_name': franchise_info.get('franchise_name', f'Franchise {franchise_id}'),\n",
    "        'franchise_age_years': franchise_age,\n",
    "        'total_transactions': franchise['total_transactions'],\n",
    "        'total_revenue': franchise['total_revenue'],\n",
    "        'growth_rate_percent': growth_rate,\n",
    "        'monthly_trends': monthly_data,\n",
    "        'avg_monthly_revenue': franchise['total_revenue'] / len(monthly_data) if monthly_data else 0\n",
    "    })\n",
    "\n",
    "# Sort results\n",
    "growth_analysis.sort(key=lambda x: x['growth_rate_percent'], reverse=True)\n",
    "top_performers = sorted(growth_analysis, key=lambda x: x['total_revenue'], reverse=True)[:10]\n",
    "\n",
    "# Final results\n",
    "total_query_time = mongo_query_time + neo4j_query_time\n",
    "\n",
    "results = {\n",
    "    'analysis_period_months': months_back,\n",
    "    'franchise_growth': growth_analysis,\n",
    "    'top_performers': top_performers,\n",
    "    'query_performance': {\n",
    "        'mongo_query_time_seconds': round(mongo_query_time, 3),\n",
    "        'neo4j_query_time_seconds': round(neo4j_query_time, 3),\n",
    "        'total_query_time_seconds': round(total_query_time, 3)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print query times for monitoring\n",
    "print(f\"MongoDB query took: {mongo_query_time:.3f} seconds\")\n",
    "print(f\"Neo4j query took: {neo4j_query_time:.3f} seconds\")\n",
    "print(f\"Total database query time: {total_query_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb90a63",
   "metadata": {},
   "source": [
    "##### Unused ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data MongoDB\n",
    "data = list(collection.find())\n",
    "dbMongo = pd.DataFrame(data)\n",
    "dbMongo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data neo4j\n",
    "query = \"MATCH (d:Daerah) RETURN d\"\n",
    "result = session.run(query)\n",
    "\n",
    "dataneo4j = []\n",
    "\n",
    "for record in result:\n",
    "    node = record[\"d\"]\n",
    "    dataneo4j.append(node._properties)\n",
    "\n",
    "dbNeo4j = pd.DataFrame(dataneo4j)\n",
    "dbNeo4j.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f101f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbMongo['id_franchise'] = dbMongo['id_franchise'].astype(str)\n",
    "dbNeo4j['id_cafe'] = dbNeo4j['id_cafe'].astype(str)\n",
    "\n",
    "dbMerge = pd.merge(dbMongo, dbNeo4j, left_on='id_franchise', right_on='id_cafe', how='inner')\n",
    "dbMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pipeline_barchart(\n",
    "    collection,\n",
    "    pipeline,\n",
    "    x_field=\"count\",\n",
    "    y_field=\"_id\",\n",
    "    title=\"Bar Chart dari Pipeline MongoDB\",\n",
    "    x_label=\"Jumlah\",\n",
    "    y_label=\"Kategori\",\n",
    "    color_scale=\"plasma\"\n",
    "):\n",
    "\n",
    "    hasil = list(collection.aggregate(pipeline))\n",
    "    df = pd.DataFrame(hasil)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Hasil pipeline kosong.\")\n",
    "        return\n",
    "\n",
    "    fig = px.bar(\n",
    "        df,\n",
    "        x=x_field,\n",
    "        y=y_field,\n",
    "        orientation=\"h\",\n",
    "        text=x_field,\n",
    "        color=x_field,\n",
    "        color_continuous_scale=color_scale,\n",
    "        labels={x_field: x_label, y_field: y_label},\n",
    "        title=title\n",
    "    )\n",
    "\n",
    "    fig.update_traces(textposition=\"outside\")\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(type=\"category\", autorange=\"reversed\"),\n",
    "        coloraxis_showscale=False,\n",
    "        xaxis_title=x_label,\n",
    "        yaxis_title=y_label\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee816356",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\"$group\":{\"_id\": \"$id_franchise\",\"count\": {\"$sum\": 1}}},\n",
    "    {\"$sort\":{\"count\": -1}},\n",
    "    {\"$limit\":5}\n",
    "]\n",
    "\n",
    "plot_pipeline_barchart(\n",
    "    collection=collection,\n",
    "    pipeline=pipeline,\n",
    "    x_field=\"count\",\n",
    "    y_field=\"_id\",\n",
    "    title=\"Top 5 Franchise dengan Transaksi Terbanyak\",\n",
    "    x_label=\"Jumlah Transaksi\",\n",
    "    y_label=\"ID Franchise\",\n",
    "    color_scale=\"teal\" \\\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45400d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Validating data structure...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA VALIDATION ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting comprehensive analysis...\n",
      "INFO:__main__:Starting employee performance analysis for period: 2020-01-01 to 2025-12-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"mongodb\": {\n",
      "    \"sample_structure\": {\n",
      "      \"fields\": [\n",
      "        \"_id\",\n",
      "        \"id_transaction\",\n",
      "        \"product\",\n",
      "        \"name\",\n",
      "        \"order_quantity\",\n",
      "        \"id_franchise\",\n",
      "        \"id_employee\",\n",
      "        \"transaction_date\"\n",
      "      ],\n",
      "      \"has_product_info\": true,\n",
      "      \"product_is_array\": true,\n",
      "      \"has_employee_info\": true,\n",
      "      \"has_franchise_info\": true\n",
      "    },\n",
      "    \"total_documents\": 163500,\n",
      "    \"sample_product_structure\": [\n",
      "      {\n",
      "        \"id_product\": \"C5\",\n",
      "        \"name\": \"Mocha\",\n",
      "        \"quantity\": 3\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"neo4j\": {\n",
      "    \"node_counts\": {\n",
      "      \"Employee\": 50,\n",
      "      \"Product\": 10,\n",
      "      \"Franchise\": 10\n",
      "    }\n",
      "  },\n",
      "  \"recommendations\": []\n",
      "}\n",
      "\n",
      "=== RUNNING COMPREHENSIVE ANALYSIS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 3, column: 22, offset: 53} for query: '\\n            MATCH (e:Employee)\\n            RETURN e.id as employee_id, e.name as employee_name, \\n                   e.work_start_hour as start_hour, e.work_end_hour as end_hour,\\n                   e.id_cafe as cafe_id\\n            '\n",
      "INFO:__main__:✓ Employee performance analysis completed\n",
      "INFO:__main__:Starting regional product analysis...\n",
      "INFO:__main__:✓ Regional product analysis completed\n",
      "INFO:__main__:Starting franchise growth analysis...\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 3, column: 10, offset: 42} for query: '\\n            MATCH (f:Franchise)\\n            RETURN f.id as franchise_id, f.name as franchise_name, \\n                   f.year_established as year_established\\n            '\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: year_established)} {position: line: 4, column: 10, offset: 98} for query: '\\n            MATCH (f:Franchise)\\n            RETURN f.id as franchise_id, f.name as franchise_name, \\n                   f.year_established as year_established\\n            '\n",
      "INFO:__main__:✓ Franchise growth analysis completed\n",
      "INFO:__main__:Starting cross-selling analysis...\n",
      "INFO:__main__:✓ Cross-selling analysis completed\n",
      "INFO:__main__:Starting customer segmentation analysis...\n",
      "INFO:__main__:✓ Customer segmentation completed\n",
      "INFO:__main__:Running MongoDB-only analysis...\n",
      "INFO:__main__:✓ MongoDB analysis completed\n",
      "INFO:__main__:Comprehensive analysis completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to: fixed_analysis_results_20250526_153940.json\n",
      "\n",
      "=== ANALYSIS SUMMARY ===\n",
      "✓ Employee Performance: Success\n",
      "  - 40 employees analyzed\n",
      "  - Top performer: Employee 48 (₹234,061.64/hour)\n",
      "✓ Regional Products: Success\n",
      "  - 10 franchises analyzed\n",
      "✓ Franchise Growth: Success\n",
      "✓ Cross Selling: Success\n",
      "✓ Customer Segmentation: Success\n",
      "  - 85954 customers segmented\n",
      "    • Regular: 775 customers\n",
      "    • Occasional: 18670 customers\n",
      "    • VIP: 175 customers\n",
      "    • New: 66334 customers\n",
      "✓ Mongodb Analysis: Success\n",
      "  - 163,500 total transactions processed\n",
      "\n",
      "=== DETAILED RESULTS SAVED TO: fixed_analysis_results_20250526_153940.json ===\n",
      "Database connections closed.\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MongoNeo4jAggregator:\n",
    "    def __init__(self, mongo_uri: str, neo4j_uri: str, neo4j_user: str, neo4j_password: str):\n",
    "        \"\"\"\n",
    "        Initialize connections to MongoDB and Neo4j\n",
    "        \"\"\"\n",
    "        # MongoDB Connection\n",
    "        self.mongo_client = pymongo.MongoClient(mongo_uri)\n",
    "        self.mongo_db = self.mongo_client['dbcafe']\n",
    "        self.transactions_collection = self.mongo_db['transactionlog']\n",
    "        \n",
    "        # Neo4j Connection\n",
    "        self.neo4j_driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))\n",
    "        \n",
    "        # Product price mapping (since prices aren't in MongoDB)\n",
    "        self.product_prices = {\n",
    "            \"C1\": 25000,  # Americano\n",
    "            \"C2\": 35000,  # Cappuccino\n",
    "            \"C3\": 40000,  # Latte\n",
    "            \"C4\": 20000,  # Espresso\n",
    "            \"C5\": 30000,  # Macchiato\n",
    "            \"C6\": 38000,  # Flat White\n",
    "            \"C7\": 45000,  # Mocha\n",
    "            \"C8\": 35000,  # Cold Brew\n",
    "            \"NC1\": 42000, # Matcha Latte\n",
    "            \"NC2\": 40000  # Chai Latte\n",
    "        }\n",
    "        \n",
    "    def close_connections(self):\n",
    "        \"\"\"Close database connections\"\"\"\n",
    "        self.mongo_client.close()\n",
    "        self.neo4j_driver.close()\n",
    "\n",
    "    def get_product_price(self, product_id: str) -> int:\n",
    "        \"\"\"Get product price with fallback\"\"\"\n",
    "        return self.product_prices.get(product_id, 30000)  # Default 30k\n",
    "\n",
    "    # ========== FIXED IDEA 1: Employee Performance Analysis ==========\n",
    "    def employee_performance_analysis(self, start_date: str, end_date: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze employee performance by combining transaction data from MongoDB \n",
    "        with employee work schedule from Neo4j KG\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting employee performance analysis for period: {start_date} to {end_date}\")\n",
    "        \n",
    "        # Get transaction data from MongoDB with enhanced date analysis\n",
    "        mongo_pipeline = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"transaction_date\": {\n",
    "                        \"$gte\": start_date,\n",
    "                        \"$lte\": end_date\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"calculated_revenue\": {\n",
    "                        \"$multiply\": [\n",
    "                            \"$order_quantity\", \n",
    "                            30000  # Fixed price instead of trying to access non-existent field\n",
    "                        ]\n",
    "                    },\n",
    "                    \"transaction_year\": {\"$substr\": [\"$transaction_date\", 0, 4]},\n",
    "                    \"transaction_month\": {\"$substr\": [\"$transaction_date\", 5, 2]},\n",
    "                    \"transaction_day_of_week\": {\"$dayOfWeek\": {\"$dateFromString\": {\"dateString\": \"$transaction_date\"}}}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$id_employee\",\n",
    "                    \"total_transactions\": {\"$sum\": 1},\n",
    "                    \"total_revenue\": {\"$sum\": \"$calculated_revenue\"},\n",
    "                    \"avg_order_quantity\": {\"$avg\": \"$order_quantity\"},\n",
    "                    \"franchise_id\": {\"$first\": \"$id_franchise\"},\n",
    "                    \"first_transaction\": {\"$min\": \"$transaction_date\"},\n",
    "                    \"last_transaction\": {\"$max\": \"$transaction_date\"},\n",
    "                    \"active_years\": {\"$addToSet\": \"$transaction_year\"},\n",
    "                    \"active_months\": {\"$addToSet\": \"$transaction_month\"},\n",
    "                    \"transactions_by_day\": {\n",
    "                        \"$push\": {\n",
    "                            \"date\": \"$transaction_date\",\n",
    "                            \"revenue\": \"$calculated_revenue\",\n",
    "                            \"quantity\": \"$order_quantity\",\n",
    "                            \"day_of_week\": \"$transaction_day_of_week\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"years_active\": {\"$size\": \"$active_years\"},\n",
    "                    \"months_active\": {\"$size\": \"$active_months\"},\n",
    "                    \"days_between_first_last\": {\n",
    "                        \"$divide\": [\n",
    "                            {\"$subtract\": [\n",
    "                                {\"$dateFromString\": {\"dateString\": \"$last_transaction\"}},\n",
    "                                {\"$dateFromString\": {\"dateString\": \"$first_transaction\"}}\n",
    "                            ]},\n",
    "                            1000 * 60 * 60 * 24  # Convert milliseconds to days\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        mongo_results = list(self.transactions_collection.aggregate(mongo_pipeline))\n",
    "        \n",
    "        # Get employee data from Neo4j\n",
    "        with self.neo4j_driver.session() as session:\n",
    "            neo4j_query = \"\"\"\n",
    "            MATCH (e:Employee)\n",
    "            RETURN e.id as employee_id, e.name as employee_name, \n",
    "                   e.work_start_hour as start_hour, e.work_end_hour as end_hour,\n",
    "                   e.id_cafe as cafe_id\n",
    "            \"\"\"\n",
    "            try:\n",
    "                neo4j_results = session.run(neo4j_query).data()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Neo4j query failed, using empty results: {e}\")\n",
    "                neo4j_results = []\n",
    "        \n",
    "        # Combine results with enhanced date-based metrics\n",
    "        combined_results = []\n",
    "        for mongo_emp in mongo_results:\n",
    "            emp_id = mongo_emp['_id']\n",
    "            neo4j_emp = next((e for e in neo4j_results if e['employee_id'] == emp_id), None)\n",
    "            \n",
    "            # Calculate time-based metrics\n",
    "            total_active_days = max(1, mongo_emp.get('days_between_first_last', 1))\n",
    "            avg_daily_revenue = mongo_emp['total_revenue'] / total_active_days\n",
    "            avg_transactions_per_day = mongo_emp['total_transactions'] / total_active_days\n",
    "            \n",
    "            # Calculate consistency score (lower standard deviation = more consistent)\n",
    "            daily_revenues = [t['revenue'] for t in mongo_emp['transactions_by_day']]\n",
    "            if len(daily_revenues) > 1:\n",
    "                mean_revenue = sum(daily_revenues) / len(daily_revenues)\n",
    "                variance = sum((x - mean_revenue) ** 2 for x in daily_revenues) / len(daily_revenues)\n",
    "                std_dev = variance ** 0.5\n",
    "                consistency_score = 1 / (1 + std_dev / mean_revenue) if mean_revenue > 0 else 0\n",
    "            else:\n",
    "                consistency_score = 1.0\n",
    "            \n",
    "            if neo4j_emp:\n",
    "                # Parse work hours (assuming format like \"07:00\")\n",
    "                try:\n",
    "                    start_hour = int(str(neo4j_emp['start_hour']).split(':')[0])\n",
    "                    end_hour = int(str(neo4j_emp['end_hour']).split(':')[0])\n",
    "                    work_hours_per_day = end_hour - start_hour\n",
    "                except:\n",
    "                    work_hours_per_day = 8  # Default\n",
    "                \n",
    "                # Calculate total work hours in period\n",
    "                total_work_hours = work_hours_per_day * total_active_days\n",
    "                performance_score = mongo_emp['total_revenue'] / total_work_hours if total_work_hours > 0 else 0\n",
    "                revenue_per_hour = performance_score\n",
    "                \n",
    "                combined_results.append({\n",
    "                    'employee_id': emp_id,\n",
    "                    'employee_name': neo4j_emp['employee_name'],\n",
    "                    'cafe_id': neo4j_emp.get('cafe_id', 'Unknown'),\n",
    "                    'total_transactions': mongo_emp['total_transactions'],\n",
    "                    'total_revenue': mongo_emp['total_revenue'],\n",
    "                    'avg_order_quantity': mongo_emp['avg_order_quantity'],\n",
    "                    'work_hours_per_day': work_hours_per_day,\n",
    "                    'total_active_days': total_active_days,\n",
    "                    'total_work_hours': total_work_hours,\n",
    "                    'performance_score': performance_score,\n",
    "                    'revenue_per_hour': revenue_per_hour,\n",
    "                    'avg_daily_revenue': avg_daily_revenue,\n",
    "                    'avg_transactions_per_day': avg_transactions_per_day,\n",
    "                    'consistency_score': consistency_score,\n",
    "                    'years_active': mongo_emp['years_active'],\n",
    "                    'months_active': mongo_emp['months_active'],\n",
    "                    'first_transaction': mongo_emp['first_transaction'],\n",
    "                    'last_transaction': mongo_emp['last_transaction'],\n",
    "                    'activity_period_days': total_active_days\n",
    "                })\n",
    "            else:\n",
    "                # Include MongoDB data even if Neo4j data is missing\n",
    "                default_work_hours_per_day = 8\n",
    "                total_work_hours = default_work_hours_per_day * total_active_days\n",
    "                performance_score = mongo_emp['total_revenue'] / total_work_hours\n",
    "                \n",
    "                combined_results.append({\n",
    "                    'employee_id': emp_id,\n",
    "                    'employee_name': f'Employee {emp_id}',\n",
    "                    'cafe_id': mongo_emp.get('franchise_id', 'Unknown'),\n",
    "                    'total_transactions': mongo_emp['total_transactions'],\n",
    "                    'total_revenue': mongo_emp['total_revenue'],\n",
    "                    'avg_order_quantity': mongo_emp['avg_order_quantity'],\n",
    "                    'work_hours_per_day': default_work_hours_per_day,\n",
    "                    'total_active_days': total_active_days,\n",
    "                    'total_work_hours': total_work_hours,\n",
    "                    'performance_score': performance_score,\n",
    "                    'revenue_per_hour': performance_score,\n",
    "                    'avg_daily_revenue': avg_daily_revenue,\n",
    "                    'avg_transactions_per_day': avg_transactions_per_day,\n",
    "                    'consistency_score': consistency_score,\n",
    "                    'years_active': mongo_emp['years_active'],\n",
    "                    'months_active': mongo_emp['months_active'],\n",
    "                    'first_transaction': mongo_emp['first_transaction'],\n",
    "                    'last_transaction': mongo_emp['last_transaction'],\n",
    "                    'activity_period_days': total_active_days\n",
    "                })\n",
    "        \n",
    "        # Sort by performance score (revenue per hour) - primary metric\n",
    "        sorted_results = sorted(combined_results, key=lambda x: x['performance_score'], reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'analysis_period': f\"{start_date} to {end_date}\",\n",
    "            'total_employees_analyzed': len(sorted_results),\n",
    "            'employee_performance': sorted_results,\n",
    "            'performance_summary': {\n",
    "                'best_performer': sorted_results[0] if sorted_results else None,\n",
    "                'worst_performer': sorted_results[-1] if sorted_results else None,\n",
    "                'avg_performance_score': sum(emp['performance_score'] for emp in sorted_results) / len(sorted_results) if sorted_results else 0,\n",
    "                'most_consistent': max(sorted_results, key=lambda x: x['consistency_score']) if sorted_results else None,\n",
    "                'most_active_days': max(sorted_results, key=lambda x: x['total_active_days']) if sorted_results else None\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # ========== FIXED IDEA 2: Regional Product Popularity ==========\n",
    "    def regional_product_analysis(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze product popularity across different regions\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting regional product analysis...\")\n",
    "        \n",
    "        # Since location data is missing from sample, we'll analyze by franchise\n",
    "        mongo_pipeline = [\n",
    "            {\n",
    "                \"$unwind\": \"$product\"  # Unwind the product array\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": {\n",
    "                        \"franchise_id\": \"$id_franchise\",\n",
    "                        \"product_id\": \"$product.id_product\",\n",
    "                        \"product_name\": \"$product.name\"\n",
    "                    },\n",
    "                    \"total_quantity\": {\"$sum\": \"$product.quantity\"},\n",
    "                    \"total_orders\": {\"$sum\": 1},\n",
    "                    \"avg_order_size\": {\"$avg\": \"$order_quantity\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$_id.franchise_id\",\n",
    "                    \"products\": {\n",
    "                        \"$push\": {\n",
    "                            \"product_id\": \"$_id.product_id\",\n",
    "                            \"product_name\": \"$_id.product_name\",\n",
    "                            \"total_quantity\": \"$total_quantity\",\n",
    "                            \"total_orders\": \"$total_orders\",\n",
    "                            \"avg_order_size\": \"$avg_order_size\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"franchise_total_orders\": {\"$sum\": \"$total_orders\"}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        mongo_results = list(self.transactions_collection.aggregate(mongo_pipeline))\n",
    "        \n",
    "        # Get product category data from Neo4j\n",
    "        with self.neo4j_driver.session() as session:\n",
    "            neo4j_query = \"\"\"\n",
    "            MATCH (p:Product)\n",
    "            RETURN p.id_product as product_id, p.name as product_name, \n",
    "                   p.category as category, p.price as price\n",
    "            \"\"\"\n",
    "            try:\n",
    "                product_data = {item['product_id']: item for item in session.run(neo4j_query).data()}\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to get product data from Neo4j: {e}\")\n",
    "                product_data = {}\n",
    "        \n",
    "        # Enhance results with product categories\n",
    "        enhanced_results = []\n",
    "        for franchise_data in mongo_results:\n",
    "            enhanced_products = []\n",
    "            for product in franchise_data['products']:\n",
    "                product_info = product_data.get(product['product_id'], {})\n",
    "                enhanced_product = {\n",
    "                    **product,\n",
    "                    'category': product_info.get('category', 'Coffee'),  # Default category\n",
    "                    'price': self.get_product_price(product['product_id']),\n",
    "                    'popularity_score': product['total_orders'] / franchise_data['franchise_total_orders'] if franchise_data['franchise_total_orders'] > 0 else 0\n",
    "                }\n",
    "                enhanced_products.append(enhanced_product)\n",
    "            \n",
    "            enhanced_results.append({\n",
    "                'franchise_id': franchise_data['_id'],\n",
    "                'total_orders': franchise_data['franchise_total_orders'],\n",
    "                'products': sorted(enhanced_products, key=lambda x: x['popularity_score'], reverse=True)\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'franchise_analysis': enhanced_results,\n",
    "            'top_franchises': sorted(enhanced_results, key=lambda x: x['total_orders'], reverse=True)[:5]\n",
    "        }\n",
    "\n",
    "    # ========== FIXED IDEA 3: Franchise Growth Analysis ==========\n",
    "    def franchise_growth_analysis(self, months_back: int = 12) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze franchise growth trends\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting franchise growth analysis...\")\n",
    "        \n",
    "        # Calculate date range\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=months_back * 30)\n",
    "        \n",
    "        # Get monthly transaction trends from MongoDB\n",
    "        mongo_pipeline = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"transaction_date\": {\n",
    "                        \"$gte\": start_date.strftime(\"%Y-%m-%d\"),\n",
    "                        \"$lte\": end_date.strftime(\"%Y-%m-%d\")\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"month_year\": {\"$substr\": [\"$transaction_date\", 0, 7]},  # Extract YYYY-MM\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": {\n",
    "                        \"franchise_id\": \"$id_franchise\",\n",
    "                        \"month\": \"$month_year\"\n",
    "                    },\n",
    "                    \"monthly_transactions\": {\"$sum\": 1},\n",
    "                    \"monthly_revenue\": {\"$sum\": \"$calculated_revenue\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$_id.franchise_id\",\n",
    "                    \"monthly_data\": {\n",
    "                        \"$push\": {\n",
    "                            \"month\": \"$_id.month\",\n",
    "                            \"transactions\": \"$monthly_transactions\",\n",
    "                            \"revenue\": \"$monthly_revenue\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"total_transactions\": {\"$sum\": \"$monthly_transactions\"},\n",
    "                    \"total_revenue\": {\"$sum\": \"$monthly_revenue\"}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        mongo_results = list(self.transactions_collection.aggregate(mongo_pipeline))\n",
    "        \n",
    "        # Get franchise data from Neo4j\n",
    "        with self.neo4j_driver.session() as session:\n",
    "            neo4j_query = \"\"\"\n",
    "            MATCH (f:Franchise)\n",
    "            RETURN f.id as franchise_id, f.name as franchise_name, \n",
    "                   f.year_established as year_established\n",
    "            \"\"\"\n",
    "            try:\n",
    "                franchise_data = {item['franchise_id']: item for item in session.run(neo4j_query).data()}\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to get franchise data: {e}\")\n",
    "                franchise_data = {}\n",
    "        \n",
    "        # Calculate growth metrics\n",
    "        growth_analysis = []\n",
    "        for franchise_info in mongo_results:\n",
    "            franchise_id = franchise_info['_id']\n",
    "            neo4j_info = franchise_data.get(franchise_id, {})\n",
    "            \n",
    "            # Calculate growth trend\n",
    "            monthly_data = sorted(franchise_info['monthly_data'], key=lambda x: x['month'])\n",
    "            if len(monthly_data) >= 2:\n",
    "                first_month_revenue = monthly_data[0]['revenue']\n",
    "                last_month_revenue = monthly_data[-1]['revenue']\n",
    "                growth_rate = ((last_month_revenue - first_month_revenue) / first_month_revenue * 100) if first_month_revenue > 0 else 0\n",
    "            else:\n",
    "                growth_rate = 0\n",
    "            \n",
    "            franchise_age = datetime.now().year - neo4j_info.get('year_established', datetime.now().year)\n",
    "            \n",
    "            growth_analysis.append({\n",
    "                'franchise_id': franchise_id,\n",
    "                'franchise_name': neo4j_info.get('franchise_name', f'Franchise {franchise_id}'),\n",
    "                'franchise_age_years': franchise_age,\n",
    "                'total_transactions': franchise_info['total_transactions'],\n",
    "                'total_revenue': franchise_info['total_revenue'],\n",
    "                'growth_rate_percent': growth_rate,\n",
    "                'monthly_trends': monthly_data,\n",
    "                'avg_monthly_revenue': franchise_info['total_revenue'] / len(monthly_data) if monthly_data else 0\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'analysis_period_months': months_back,\n",
    "            'franchise_growth': sorted(growth_analysis, key=lambda x: x['growth_rate_percent'], reverse=True),\n",
    "            'top_performers': sorted(growth_analysis, key=lambda x: x['total_revenue'], reverse=True)[:10]\n",
    "        }\n",
    "\n",
    "    # ========== NEW: Time-based Performance Analysis ==========\n",
    "    def time_based_performance_analysis(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze employee performance trends over time periods\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting time-based performance analysis...\")\n",
    "        \n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]},\n",
    "                    \"transaction_year\": {\"$substr\": [\"$transaction_date\", 0, 4]},\n",
    "                    \"transaction_month\": {\"$substr\": [\"$transaction_date\", 5, 2]},\n",
    "                    \"transaction_quarter\": {\n",
    "                        \"$switch\": {\n",
    "                            \"branches\": [\n",
    "                                {\"case\": {\"$in\": [{\"$substr\": [\"$transaction_date\", 5, 2]}, [\"01\", \"02\", \"03\"]]}, \"then\": \"Q1\"},\n",
    "                                {\"case\": {\"$in\": [{\"$substr\": [\"$transaction_date\", 5, 2]}, [\"04\", \"05\", \"06\"]]}, \"then\": \"Q2\"},\n",
    "                                {\"case\": {\"$in\": [{\"$substr\": [\"$transaction_date\", 5, 2]}, [\"07\", \"08\", \"09\"]]}, \"then\": \"Q3\"},\n",
    "                                {\"case\": {\"$in\": [{\"$substr\": [\"$transaction_date\", 5, 2]}, [\"10\", \"11\", \"12\"]]}, \"then\": \"Q4\"}\n",
    "                            ],\n",
    "                            \"default\": \"Unknown\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": {\n",
    "                        \"employee_id\": \"$id_employee\",\n",
    "                        \"year\": \"$transaction_year\",\n",
    "                        \"quarter\": \"$transaction_quarter\"\n",
    "                    },\n",
    "                    \"quarterly_transactions\": {\"$sum\": 1},\n",
    "                    \"quarterly_revenue\": {\"$sum\": \"$calculated_revenue\"},\n",
    "                    \"avg_order_quantity\": {\"$avg\": \"$order_quantity\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$_id.employee_id\",\n",
    "                    \"quarterly_performance\": {\n",
    "                        \"$push\": {\n",
    "                            \"year\": \"$_id.year\",\n",
    "                            \"quarter\": \"$_id.quarter\",\n",
    "                            \"transactions\": \"$quarterly_transactions\",\n",
    "                            \"revenue\": \"$quarterly_revenue\",\n",
    "                            \"avg_order_quantity\": \"$avg_order_quantity\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"total_quarters_active\": {\"$sum\": 1},\n",
    "                    \"total_revenue_all_time\": {\"$sum\": \"$quarterly_revenue\"},\n",
    "                    \"total_transactions_all_time\": {\"$sum\": \"$quarterly_transactions\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"avg_quarterly_revenue\": {\"$divide\": [\"$total_revenue_all_time\", \"$total_quarters_active\"]},\n",
    "                    \"avg_quarterly_transactions\": {\"$divide\": [\"$total_transactions_all_time\", \"$total_quarters_active\"]}\n",
    "                }\n",
    "            },\n",
    "            {\"$sort\": {\"total_revenue_all_time\": -1}}\n",
    "        ]\n",
    "        \n",
    "        time_results = list(self.transactions_collection.aggregate(pipeline))\n",
    "        \n",
    "        return {\n",
    "            'time_based_analysis': time_results,\n",
    "            'summary': {\n",
    "                'total_employees': len(time_results),\n",
    "                'most_consistent_performer': max(time_results, key=lambda x: x['total_quarters_active']) if time_results else None\n",
    "            }\n",
    "        }\n",
    "    def cross_selling_analysis(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Identify cross-selling opportunities by analyzing product combinations\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting cross-selling analysis...\")\n",
    "        \n",
    "        # Get multi-product transactions\n",
    "        multi_product_pipeline = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"$expr\": {\"$gt\": [{\"$size\": \"$product\"}, 1]}  # More than 1 product\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"id_transaction\": 1,\n",
    "                    \"product_ids\": \"$product.id_product\",\n",
    "                    \"id_franchise\": 1,\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        multi_product_transactions = list(self.transactions_collection.aggregate(multi_product_pipeline))\n",
    "        \n",
    "        # Get product data from Neo4j\n",
    "        with self.neo4j_driver.session() as session:\n",
    "            neo4j_query = \"\"\"\n",
    "            MATCH (p:Product)\n",
    "            RETURN p.id_product as product_id, p.name as product_name, \n",
    "                   p.category as category\n",
    "            \"\"\"\n",
    "            try:\n",
    "                products = {item['product_id']: item for item in session.run(neo4j_query).data()}\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to get product data: {e}\")\n",
    "                products = {}\n",
    "        \n",
    "        # Analyze product combinations\n",
    "        product_combinations = {}\n",
    "        \n",
    "        for transaction in multi_product_transactions:\n",
    "            products_in_transaction = transaction['product_ids']\n",
    "            \n",
    "            # Analyze product pairs\n",
    "            for i, product1 in enumerate(products_in_transaction):\n",
    "                for product2 in products_in_transaction[i+1:]:\n",
    "                    pair = tuple(sorted([product1, product2]))\n",
    "                    product_combinations[pair] = product_combinations.get(pair, 0) + 1\n",
    "        \n",
    "        # Sort and format results\n",
    "        top_product_pairs = sorted(product_combinations.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "        \n",
    "        formatted_product_pairs = []\n",
    "        for (prod1, prod2), count in top_product_pairs:\n",
    "            prod1_info = products.get(prod1, {})\n",
    "            prod2_info = products.get(prod2, {})\n",
    "            formatted_product_pairs.append({\n",
    "                'product1': {'id': prod1, 'name': prod1_info.get('product_name', f'Product {prod1}')},\n",
    "                'product2': {'id': prod2, 'name': prod2_info.get('product_name', f'Product {prod2}')},\n",
    "                'frequency': count,\n",
    "                'confidence': count / len(multi_product_transactions) if multi_product_transactions else 0\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'analysis_summary': {\n",
    "                'total_multi_product_transactions': len(multi_product_transactions),\n",
    "                'unique_product_combinations': len(product_combinations)\n",
    "            },\n",
    "            'top_product_combinations': formatted_product_pairs\n",
    "        }\n",
    "\n",
    "    # ========== FIXED MongoDB-Only Analysis ==========\n",
    "    def mongodb_only_analysis(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Comprehensive analysis using only MongoDB data\n",
    "        \"\"\"\n",
    "        logger.info(\"Running MongoDB-only analysis...\")\n",
    "        \n",
    "        # Transaction summary\n",
    "        total_transactions = self.transactions_collection.count_documents({})\n",
    "        \n",
    "        # Top employees by transaction count\n",
    "        employee_pipeline = [\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$id_employee\",\n",
    "                    \"transaction_count\": {\"$sum\": 1},\n",
    "                    \"total_revenue\": {\"$sum\": \"$calculated_revenue\"},\n",
    "                    \"avg_order_quantity\": {\"$avg\": \"$order_quantity\"}\n",
    "                }\n",
    "            },\n",
    "            {\"$sort\": {\"total_revenue\": -1}},\n",
    "            {\"$limit\": 10}\n",
    "        ]\n",
    "        \n",
    "        top_employees = list(self.transactions_collection.aggregate(employee_pipeline))\n",
    "        \n",
    "        # Top products (unwind the array first)\n",
    "        product_pipeline = [\n",
    "            {\"$unwind\": \"$product\"},\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$product.id_product\",\n",
    "                    \"product_name\": {\"$first\": \"$product.name\"},\n",
    "                    \"total_quantity\": {\"$sum\": \"$product.quantity\"},\n",
    "                    \"order_count\": {\"$sum\": 1}\n",
    "                }\n",
    "            },\n",
    "            {\"$sort\": {\"total_quantity\": -1}},\n",
    "            {\"$limit\": 10}\n",
    "        ]\n",
    "        \n",
    "        top_products = list(self.transactions_collection.aggregate(product_pipeline))\n",
    "        \n",
    "        # Franchise analysis\n",
    "        franchise_pipeline = [\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$id_franchise\",\n",
    "                    \"transaction_count\": {\"$sum\": 1},\n",
    "                    \"total_revenue\": {\"$sum\": \"$calculated_revenue\"}\n",
    "                }\n",
    "            },\n",
    "            {\"$sort\": {\"total_revenue\": -1}},\n",
    "            {\"$limit\": 10}\n",
    "        ]\n",
    "        \n",
    "        top_franchises = list(self.transactions_collection.aggregate(franchise_pipeline))\n",
    "        \n",
    "        return {\n",
    "            'summary': {\n",
    "                'total_transactions': total_transactions,\n",
    "                'analysis_type': 'MongoDB Only'\n",
    "            },\n",
    "            'top_employees': top_employees,\n",
    "            'top_products': top_products,\n",
    "            'top_franchises': top_franchises\n",
    "        }\n",
    "\n",
    "    # ========== FIXED Customer Segmentation ==========\n",
    "    def customer_segmentation_analysis(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Segment customers based on transaction patterns\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting customer segmentation analysis...\")\n",
    "        \n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"calculated_revenue\": {\"$multiply\": [\"$order_quantity\", 30000]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$name\",  # Customer name as identifier\n",
    "                    \"total_spent\": {\"$sum\": \"$calculated_revenue\"},\n",
    "                    \"transaction_count\": {\"$sum\": 1},\n",
    "                    \"avg_order_value\": {\"$avg\": \"$calculated_revenue\"},\n",
    "                    \"preferred_franchises\": {\"$addToSet\": \"$id_franchise\"},\n",
    "                    \"last_transaction\": {\"$max\": \"$transaction_date\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"customer_segment\": {\n",
    "                        \"$switch\": {\n",
    "                            \"branches\": [\n",
    "                                {\n",
    "                                    \"case\": {\"$and\": [{\"$gte\": [\"$total_spent\", 500000]}, {\"$gte\": [\"$transaction_count\", 20]}]},\n",
    "                                    \"then\": \"VIP\"\n",
    "                                },\n",
    "                                {\n",
    "                                    \"case\": {\"$and\": [{\"$gte\": [\"$total_spent\", 200000]}, {\"$gte\": [\"$transaction_count\", 10]}]},\n",
    "                                    \"then\": \"Regular\"\n",
    "                                },\n",
    "                                {\n",
    "                                    \"case\": {\"$and\": [{\"$lte\": [\"$total_spent\", 100000]}, {\"$lte\": [\"$transaction_count\", 5]}]},\n",
    "                                    \"then\": \"Occasional\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"default\": \"New\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"franchise_loyalty\": {\"$size\": \"$preferred_franchises\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$customer_segment\",\n",
    "                    \"customer_count\": {\"$sum\": 1},\n",
    "                    \"avg_total_spent\": {\"$avg\": \"$total_spent\"},\n",
    "                    \"avg_transaction_count\": {\"$avg\": \"$transaction_count\"},\n",
    "                    \"avg_order_value\": {\"$avg\": \"$avg_order_value\"}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        segmentation_results = list(self.transactions_collection.aggregate(pipeline))\n",
    "        \n",
    "        return {\n",
    "            'customer_segments': segmentation_results,\n",
    "            'total_customers': sum(segment['customer_count'] for segment in segmentation_results)\n",
    "        }\n",
    "\n",
    "    # ========== Main Analysis Runner ==========\n",
    "    def run_comprehensive_analysis(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run all analysis functions and return comprehensive results\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting comprehensive analysis...\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        try:\n",
    "            # Employee Performance Analysis\n",
    "            try:\n",
    "                results['employee_performance'] = self.employee_performance_analysis(\n",
    "                    start_date=\"2020-01-01\", \n",
    "                    end_date=\"2025-12-31\"\n",
    "                )\n",
    "                logger.info(\"✓ Employee performance analysis completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Employee performance analysis failed: {e}\")\n",
    "                results['employee_performance'] = {'error': str(e)}\n",
    "            \n",
    "            # Regional Product Analysis\n",
    "            try:\n",
    "                results['regional_products'] = self.regional_product_analysis()\n",
    "                logger.info(\"✓ Regional product analysis completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Regional product analysis failed: {e}\")\n",
    "                results['regional_products'] = {'error': str(e)}\n",
    "            \n",
    "            # Franchise Growth Analysis\n",
    "            try:\n",
    "                results['franchise_growth'] = self.franchise_growth_analysis(months_back=12)\n",
    "                logger.info(\"✓ Franchise growth analysis completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Franchise growth analysis failed: {e}\")\n",
    "                results['franchise_growth'] = {'error': str(e)}\n",
    "            \n",
    "            # Cross-selling Analysis\n",
    "            try:\n",
    "                results['cross_selling'] = self.cross_selling_analysis()\n",
    "                logger.info(\"✓ Cross-selling analysis completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Cross-selling analysis failed: {e}\")\n",
    "                results['cross_selling'] = {'error': str(e)}\n",
    "            \n",
    "            # Customer segmentation\n",
    "            try:\n",
    "                results['customer_segmentation'] = self.customer_segmentation_analysis()\n",
    "                logger.info(\"✓ Customer segmentation completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Customer segmentation failed: {e}\")\n",
    "                results['customer_segmentation'] = {'error': str(e)}\n",
    "            \n",
    "            # MongoDB-only analysis as backup\n",
    "            try:\n",
    "                results['mongodb_analysis'] = self.mongodb_only_analysis()\n",
    "                logger.info(\"✓ MongoDB analysis completed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"MongoDB analysis failed: {e}\")\n",
    "                results['mongodb_analysis'] = {'error': str(e)}\n",
    "            \n",
    "            logger.info(\"Comprehensive analysis completed!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Critical error during analysis: {str(e)}\")\n",
    "            results = {'error': 'Analysis failed', 'details': str(e)}\n",
    "        \n",
    "        return results\n",
    "\n",
    "    # ========== Data Validation ==========\n",
    "    def validate_data_structure(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate the data structure in both MongoDB and Neo4j\n",
    "        \"\"\"\n",
    "        logger.info(\"Validating data structure...\")\n",
    "        \n",
    "        validation_results = {\n",
    "            'mongodb': {},\n",
    "            'neo4j': {},\n",
    "            'recommendations': []\n",
    "        }\n",
    "        \n",
    "        # MongoDB validation\n",
    "        try:\n",
    "            sample_transaction = self.transactions_collection.find_one()\n",
    "            if sample_transaction:\n",
    "                validation_results['mongodb'] = {\n",
    "                    'sample_structure': {\n",
    "                        'fields': list(sample_transaction.keys()),\n",
    "                        'has_product_info': 'product' in sample_transaction,\n",
    "                        'product_is_array': isinstance(sample_transaction.get('product'), list),\n",
    "                        'has_employee_info': 'id_employee' in sample_transaction,\n",
    "                        'has_franchise_info': 'id_franchise' in sample_transaction\n",
    "                    },\n",
    "                    'total_documents': self.transactions_collection.count_documents({}),\n",
    "                    'sample_product_structure': sample_transaction.get('product', [])[:2] if sample_transaction.get('product') else []\n",
    "                }\n",
    "            else:\n",
    "                validation_results['mongodb']['error'] = 'No documents found'\n",
    "        except Exception as e:\n",
    "            validation_results['mongodb']['error'] = str(e)\n",
    "        \n",
    "        # Neo4j validation\n",
    "        try:\n",
    "            with self.neo4j_driver.session() as session:\n",
    "                node_counts = {}\n",
    "                for label in ['Employee', 'Product', 'Franchise']:\n",
    "                    try:\n",
    "                        result = session.run(f\"MATCH (n:{label}) RETURN count(n) as count\")\n",
    "                        node_counts[label] = result.single()['count']\n",
    "                    except Exception as e:\n",
    "                        node_counts[label] = f\"Error: {e}\"\n",
    "                \n",
    "                validation_results['neo4j']['node_counts'] = node_counts\n",
    "                \n",
    "        except Exception as e:\n",
    "            validation_results['neo4j']['error'] = str(e)\n",
    "        \n",
    "        return validation_results\n",
    "\n",
    "# ========== Usage Example ==========\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the fixed MongoNeo4jAggregator\n",
    "    \"\"\"\n",
    "    # Database connection parameters\n",
    "    MONGO_URI = \"mongodb://localhost:27017/\"\n",
    "    URI = os.getenv(\"NEO4J_URI\")\n",
    "    USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "    PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "    \n",
    "    # Initialize aggregator\n",
    "    aggregator = MongoNeo4jAggregator(\n",
    "        mongo_uri=MONGO_URI,\n",
    "        neo4j_uri=URI,\n",
    "        neo4j_user=USERNAME,\n",
    "        neo4j_password=PASSWORD\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Validate data structure first\n",
    "        print(\"=== DATA VALIDATION ===\")\n",
    "        validation = aggregator.validate_data_structure()\n",
    "        print(json.dumps(validation, indent=2, default=str))\n",
    "        \n",
    "        # Run comprehensive analysis\n",
    "        print(\"\\n=== RUNNING COMPREHENSIVE ANALYSIS ===\")\n",
    "        results = aggregator.run_comprehensive_analysis()\n",
    "        \n",
    "        # Save results to JSON file\n",
    "        output_file = f'fixed_analysis_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"\\nResults saved to: {output_file}\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n=== ANALYSIS SUMMARY ===\")\n",
    "        \n",
    "        for analysis_type, data in results.items():\n",
    "            if 'error' not in data:\n",
    "                print(f\"✓ {analysis_type.replace('_', ' ').title()}: Success\")\n",
    "                \n",
    "                # Print specific metrics for each analysis\n",
    "                if analysis_type == 'employee_performance':\n",
    "                    emp_count = len(data.get('employee_performance', []))\n",
    "                    print(f\"  - {emp_count} employees analyzed\")\n",
    "                    if emp_count > 0:\n",
    "                        top_performer = data['employee_performance'][0]\n",
    "                        print(f\"  - Top performer: {top_performer['employee_name']} (₹{top_performer['revenue_per_hour']:,.2f}/hour)\")\n",
    "                \n",
    "                elif analysis_type == 'regional_products':\n",
    "                    franchise_count = len(data.get('franchise_analysis', []))\n",
    "                    print(f\"  - {franchise_count} franchises analyzed\")\n",
    "                \n",
    "                elif analysis_type == 'customer_segmentation':\n",
    "                    total_customers = data.get('total_customers', 0)\n",
    "                    print(f\"  - {total_customers} customers segmented\")\n",
    "                    for segment in data.get('customer_segments', []):\n",
    "                        print(f\"    • {segment['_id']}: {segment['customer_count']} customers\")\n",
    "                \n",
    "                elif analysis_type == 'mongodb_analysis':\n",
    "                    total_trans = data['summary'].get('total_transactions', 0)\n",
    "                    print(f\"  - {total_trans:,} total transactions processed\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"✗ {analysis_type.replace('_', ' ').title()}: {data['error']}\")\n",
    "        \n",
    "        print(f\"\\n=== DETAILED RESULTS SAVED TO: {output_file} ===\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main execution failed: {str(e)}\")\n",
    "        print(f\"Analysis failed with error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Close connections\n",
    "        aggregator.close_connections()\n",
    "        print(\"Database connections closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
